{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03_ds3_gan_images.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNcosBW43c+cXt7n+MbTcjZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    },
    "language_info": {
      "name": "R"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mneunhoe/ds3_gan/blob/main/03_ds3_gan_images.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVrs0WARyxPP"
      },
      "source": [
        "# $\\text{DS}^3$: Generative Adversarial Nets\n",
        "(Marcel Neunhoeffer, LMU Munich)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_hlE-QEzvyH"
      },
      "source": [
        "This is the third workbook for the Data Science Summer School course \"Generative Adversarial Nets\". \n",
        "\n",
        "You can find the slides and the following workbooks for this course at: https://github.com/mneunhoe/ds3_gan\n",
        "\n",
        "\n",
        "In this workbook we will implement a Generative Adversarial Net to generate fake images.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmoQAzu61Lhn"
      },
      "source": [
        "Before we get started, we install and load some helpful packages to our R environment. Installing `torch` can take some time (around 6 minutes for me). For this tutorial to work you should choose a GPU runtime."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9s_AizUt1KQU"
      },
      "source": [
        "p_needed <- c(\"torch\", \"RGAN\", \"torchvision\", \"here\")\n",
        "packages <- rownames(installed.packages())\n",
        "p_to_install <- p_needed[!(p_needed %in% packages)]\n",
        "if (length(p_to_install) > 0) {\n",
        "  install.packages(p_to_install)\n",
        "}\n",
        "sapply(p_needed, require, character.only = TRUE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33FnQ8-QzeJ_"
      },
      "source": [
        "## A GAN to generate fake images\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOHcyGBKClg1"
      },
      "source": [
        "### Downloading and setting up the training data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phEhLlt1xDLp"
      },
      "source": [
        "In this example we will work with the celeba dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6MTeFvv18U5"
      },
      "source": [
        "if(!dir.exists(here::here(\"celeba/img_align_celeba\"))){\n",
        "# Create celeba directory in working directory\n",
        "dir.create(here::here(\"celeba\"))\n",
        "\n",
        "# Download the celeba images\n",
        "invisible(system(\n",
        "  paste0(\n",
        "    \"wget https://s3-us-west-1.amazonaws.com/udacity-dlnfd/datasets/celeba.zip -O\",\n",
        "    here::here(\"celeba/img_align_celeba.zip\")\n",
        "  ),\n",
        "  intern = TRUE\n",
        "))\n",
        "\n",
        "# Unzip the folder\n",
        "invisible(system(paste0(\n",
        "  \"unzip -o \",\n",
        "  here::here(\"celeba/img_align_celeba.zip\"),\n",
        "  \" -d \",\n",
        "  here::here(\"celeba\")\n",
        "), intern = TRUE))\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNfpDeGXUq2z"
      },
      "source": [
        "### Image preprocessing and setting up the neural networks\n",
        "In this example we will use the so called DCGAN (Deep Convolutional GAN) architecture. Since we are working with images now, this makes sense. The GAN expects that all pictures have the same size, therefore, we need to preprocess the pictures while loading a batch of images. Here we make sure that every picture is of size 64x64.\n",
        "\n",
        "If a GPU is available we would like to train on it as this significantly speeds up training."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch::torch_manual_seed(20220803)\n",
        "dataset <- torchvision::image_folder_dataset(root = here::here(\"celeba\"),\n",
        "                                             transform = function(x) {\n",
        "                                               x = torchvision::transform_to_tensor(x)\n",
        "                                               x = torchvision::transform_resize(x, size = c(64, 64))\n",
        "                                               x = torchvision::transform_center_crop(x, c(64, 64))\n",
        "                                               x = torchvision::transform_normalize(x, c(0.5, 0.5, 0.5), \n",
        "                                                                                    c(0.5, 0.5, 0.5))\n",
        "                                               return(x)\n",
        "                                             })\n",
        "\n",
        "device <- torch::torch_device(ifelse(torch::cuda_is_available(), \"cuda\", \"cpu\"))\n",
        "\n",
        "g_net <- RGAN::DCGAN_Generator(dropout_rate = 0, noise_dim = 100)$to(device = device)\n",
        "d_net <- RGAN::DCGAN_Discriminator(dropout_rate = 0, sigmoid = F)$to(device = device)\n",
        "\n",
        "\n",
        "g_optim <- torch::optim_adam(g_net$parameters, lr = 0.0002, betas = c(0.5, 0.999))\n",
        "d_optim <- torch::optim_adam(d_net$parameters, lr = 0.0002, betas = c(0.5, 0.999))\n",
        "\n",
        "noise_dim <- c(100, 1, 1)\n",
        "fixed_z <-\n",
        "  torch::torch_randn(c(16, noise_dim))$to(device = device)"
      ],
      "metadata": {
        "id": "i_tiv4_ggJ0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trained_gan <- RGAN::gan_trainer(\n",
        "  data = dataset,\n",
        "  noise_dim = noise_dim,\n",
        "  noise_distribution = \"normal\",\n",
        "  data_type = \"image\",\n",
        "  value_function = \"wasserstein\",\n",
        "  generator = g_net,\n",
        "  generator_optimizer = g_optim,\n",
        "  discriminator = d_net,\n",
        "  discriminator_optimizer = d_optim,\n",
        "  plot_progress = FALSE,\n",
        "  plot_interval = 10,\n",
        "  batch_size = 128,\n",
        "  synthetic_examples = 16,\n",
        "  device = device,\n",
        "  eval_dropout = FALSE,\n",
        "  epochs = 1\n",
        ")"
      ],
      "metadata": {
        "id": "YGBFBeThSXAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GAN_update_plot_image(synth_data = expert_sample_synthetic_data(g_net, fixed_z, device,eval_dropout = FALSE))"
      ],
      "metadata": {
        "id": "ou17nS-8TOvR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}